{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from vgg16 import model_vgg16\n",
    "from inceptionV3 import f_model_inceptionV3\n",
    "from inceptionV3 import f_model_inceptionV3\n",
    "from data_augmentation import f_data_augumentation\n",
    "from display_image_data import f_display_image_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resize_image import f_resize_raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'dataset/'\n",
    "\n",
    "raw_train_dir = os.path.join(base_dir, 'raw_train')\n",
    "raw_validation_dir = os.path.join(base_dir, 'raw_validation')\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "aug_train_dir = os.path.join(base_dir,'aug_train')\n",
    "aug_validation_dir = os.path.join(base_dir,'aug_validation')\n",
    "\n",
    "train_0 = os.path.join(base_dir,'created_image/0')\n",
    "train_1 = os.path.join(base_dir,'created_image/1')\n",
    "\n",
    "target_size_raw = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:47:50.469184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 80 images belonging to 1 classes.\n",
      "Found 59 images belonging to 1 classes.\n",
      "Found 31 images belonging to 1 classes.\n",
      "Found 3200 images belonging to 2 classes.\n",
      "Found 1800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from data_augmentation import f_data_augumentation\n",
    "target_size = (224,224)\n",
    "train_datagen, test_datagen, train_generator, validation_generator =  f_data_augumentation(train_dir, validation_dir, aug_train_dir, aug_validation_dir, target_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 6102s 195s/step - loss: 7.5047 - acc: 0.5038 - val_loss: 5.2525 - val_acc: 0.6556\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 1628s 51s/step - loss: 7.6246 - acc: 0.5000 - val_loss: 5.2525 - val_acc: 0.6556\n"
     ]
    }
   ],
   "source": [
    "from vgg16 import model_vgg16\n",
    "\n",
    "vgghist, model_vgg16 = model_vgg16(\n",
    "    train_generator, \n",
    "    validation_generator, \n",
    "    verbos=2,\n",
    "    epochs=10, \n",
    "    #batch_size=None, \n",
    "    learning_rate=0.0001,\n",
    "    verbose=2)\n",
    "    \n",
    "hist, model = vgghist, model_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_resize_raw_image(raw_train_dir+'/0',train_dir+'/0',target_size_raw)\n",
    "f_resize_raw_image(raw_train_dir+'/1',train_dir+'/1',target_size_raw)\n",
    "f_resize_raw_image(raw_validation_dir+'/0',validation_dir+'/0',target_size_raw)\n",
    "f_resize_raw_image(raw_validation_dir+'/1',validation_dir+'/1',target_size_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = os.listdir(os.path.join(raw_train_dir,'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(raw_train_dir,'0')\n",
    "ls = [ os.path.join(src_dir, i) for i in os.listdir(src_dir)]\n",
    "ls\n",
    "ls.remove(src_dir+'/.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224,224)\n",
    "tgt_dir = os.path.join(aug_train_dir,'0')\n",
    "for i, img_path in enumerate(ls):\n",
    "    print(f'[+] Processing file {img_path}...')\n",
    "    image = Image.open(img_path)\n",
    "    a = image.resize(target_size)\n",
    "    a.save(tgt_dir+'/'+str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74bfc22d74491445281827d816b7fd25a2e53486546878afd402234dcb493ba2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
